
Слишком большое количество пакетов в любой части сети может в конечном итоге привести к задержке и потере пакетов, что негативно скажется на производительности. Такая ситуация называется перегрузкой (congestion).

## Необходимость в управлении трафиком: перегрузка

**За борьбу с перегрузкой отвечают сетевой и транспортный уровни.**
Поскольку она происходит в сети, именно сетевой уровень сталкивается с ней непосредственно и определяет, что делать с лишними пакетами. Самое эффективное решение — уменьшить нагрузку на сеть со стороны транспортного уровня; это значит, что оба уровня должны работать вместе. 

Когда количество отправляемых хостами пакетов намного ниже пропускной способности сети, объем доставленного трафика пропорционален объему переданного (в два раза больше отправлено — в два раза больше получено). Но если число пакетов приближается к пределу емкости, при эпизодических всплесках трафика буферы маршрутизаторов переполняются; в итоге некоторые пакеты теряются. Потерянные пакеты расходуют часть пропускной способности, поэтому объем доставленного трафика оказывается ниже идеальной кривой. Таким образом,
в сети возникает перегрузка.
![[Pasted image 20241223114203.png]]

**В определенный момент может возникнуть коллапс сети** из-за перегрузки (congestion collapse), при котором производительность падает, поскольку абонентская нагрузка превышает пропускную способность. **Коллапс сети происходит, когда увеличение нагрузки фактически ведет к уменьшению объема успешно доставленного трафика. При этом пакеты настолько задерживаются, что становятся бесполезными к моменту их доставки.** Например, на ранних этапах существования интернета время, которое пакет проводил в очереди на отправку (при скорости 56 Кбит/с), зачастую превышало время его пребывания в сети. В результате пакет приходилось удалять. Еще один неприятный сценарий — когда отправители повторно передают сильно задержанные пакеты, полагая, что они утеряны. В этом случае пропускная способность используется неэффективно, поскольку по сети передаются копии одного и того же пакета.

**Исследования показали, что многие сетевые устройства имеют больше памяти, чем требуется. Это явление получило название излишней сетевой буферизации (bufferbloat).**
Это может снижать производительность сети по нескольким причинам. 
- Во-первых, пакеты могут долго ждать в очереди, что приводит к истечению их срока ожидания и отправке дубликатов. 
- Во-вторых, отсутствие своевременного удаления пакетов из буферов затрудняет уведомление отправителей о перегрузках, что ведет к продолжению отправки избыточного трафика. В итоге это может привести к коллапсу сети.

**Разница между понятиями** 
- контроль перегрузок» (congestion control), 
- управление трафиком» (traffic management) 
- управление потоком» (flow control)

1. **Контроль перегрузок (congestion control)**  
   Значение: Это механизм, который управляет поведением всех хостов и маршрутизаторов в сети с целью предотвращения перегрузки. Он регулирует объем трафика, чтобы избежать ситуаций, когда сеть не справляется с нагрузкой.  
	   Пример: В сети, где несколько устройств одновременно отправляют данные, контроль перегрузок может снизить скорость передачи данных у отправителей, чтобы предотвратить переполнение буферов маршрутизаторов.

2. **Управление трафиком (traffic management)**  
   Значение: Это процесс, обеспечивающий, чтобы сеть могла справляться с поступающим трафиком. Это может включать в себя действия как со стороны сетевых устройств, так и со стороны отправителей.  
	   Пример: Провайдер интернет-услуг использует управление трафиком, чтобы гарантировать, что в часы пик пользователи не испытывают значительных задержек при загрузке веб-страниц.

3. **Управление потоком (flow control)**  
   Значение: Это механизм, который регулирует скорость передачи данных между конкретными отправителями и получателями, чтобы предотвратить потерю данных из-за того, что отправитель работает быстрее, чем получатель может обрабатывать входящие данные.  
	   Пример: В ситуации, когда суперкомпьютер передает файл персональному компьютеру, управление потоком может временно приостановить передачу данных, если ПК не успевает обрабатывать получаемую информацию.


## Методы управления трафиком
Перегрузка означает, что нагрузка на сеть превышает (временно) возможности ресурсов сети (или некоторой ее части). **Существует два возможных решения:**
**увеличить объем ресурсов или снизить нагрузку.** 
Эти решения обычно применяются в разных временных рамках в зависимости
от задачи: предотвратить перегрузку или справиться с ней, если ее не удалось
избежать.
![[Pasted image 20241223133313.png]]


1. **Пропускная способность сети**  

   - Создание сети с достаточной пропускной способностью является основным способом предотвращения перегрузок.

   - Низкая пропускная способность на определенных участках сети увеличивает вероятность перегрузки.

2. **Обеспечение ресурсов (provisioning)**  

   - Динамическое добавление ресурсов, таких как маршрутизаторы или резервные линии, помогает справляться с перегрузками.

   - Обновление загруженных соединений и маршрутизаторов происходит на основе долгосрочной оценки трафика.

3. **Адаптация маршрутов**  

   - Маршруты могут быть изменены в зависимости от изменения трафика в течение дня, что помогает оптимально использовать пропускную способность.

   - Маршрутизация с учетом состояния трафика (traffic-aware routing) позволяет обходить загруженные линии.

4. **Управление допуском (admission control)**  

   - Новые соединения могут быть отклонены, если они могут привести к перегрузке сети.

   - Это позволяет контролировать количество активных соединений и предотвращать превышение возможностей сети.

5. **Обратная связь для отправителей**  

   - В случае перегрузки сеть может передавать сообщения обратной связи отправителям, чтобы они снизили скорость передачи данных.

   - Троттлинг (throttling) — это метод, при котором сеть самостоятельно замедляет трафик.

6. **Мониторинг состояния сети**  

   - Маршрутизаторы отслеживают среднюю нагрузку, время ожидания и частоту потерь пакетов для принятия решений о необходимости снижения скорости.

7. **Сброс нагрузки**  

   - В случае перегрузки сеть может удалить пакеты, которые не могут быть доставлены, чтобы предотвратить коллапс.

   - Существуют различные методы сброса нагрузки, такие как ограничение скорости конкретного отправителя и соблюдение политики трафика.

8. **Проблемы обратной связи**  

   - Своевременная доставка сообщений обратной связи является сложной задачей, требующей тщательной настройки временных параметров.

   - Неправильные настройки могут привести к колебаниям в работе системы или слишком медленной реакции на перегрузки.


#### Маршрутизация с учетом состояния трафика

**Методы маршрутизации используют фиксированные весовые коэффициенты связей, которые адаптируются к изменениям топологии, но не к изменениям нагрузки трафика. Однако нагрузку также следует учитывать при вычислении маршрутов, чтобы направлять трафик в обход наиболее подверженных перегрузке участков.**
Наиболее простой способ — сделать весовой коэффициент связи функцией от
пропускной способности связи (фиксированной) и задержки распространения,
а также измеренной (переменной) нагрузки или среднего времени ожидания
в очереди. В результате пути с наименьшим весом будут при прочих равных
параметрах наименее нагруженными.
Маршрутизация с учетом состояния трафика использовалась на ранних этапах развития интернета в рамках модели Кханны и Зинки (Khanna and Zinky,
1989). Однако здесь есть небольшая опасность.

Пример:
![[Pasted image 20241223142805.png]]
Предположим, что основной трафик между западом и востоком проходит по CF, поэтому она слишком нагружена, что приводит к длительным задержкам. Учет времени ожидания в очереди при вычислении кратчайшего пути сделает линию EI более популярной. После внесения изменений в таблицы маршрутизации большая часть трафика пойдет по EI и слишком нагруженной окажется именно эта линия. При следующем обновлении таблиц кратчайшим путем снова станет CF. В конечном итоге значения в таблицах будут сильно колебаться, что приведет к ошибкам при выборе маршрутов и другим проблемам.

#### Управление допуском

Популярный метод предотвращения перегрузки в сетях виртуальных каналов — управление допуском (admission control). Идея проста: **не создавать новый виртуальный канал до тех пор, пока сеть не сможет обработать дополнительный трафик без перегрузки.**
**Суть этого подхода в том, чтобы определить, когда добавление нового виртуального канала приведет к перегрузке.** В телефонных сетях эта задача решается просто благодаря фиксированной пропускной способности для вызовов (64 Кбит/с для несжатого аудио). Но в компьютерных сетях используются виртуальные каналы всевозможных типов. Поэтому если мы хотим прибегнуть к управлению допуском, каналы должны предоставлять информацию о характеристиках трафика.
**Располагая характеристиками трафика, сеть принимает решение о добавлении**
**нового виртуального канала.** Чтобы не произошло перегрузки, сеть может, напри-
мер, зарезервировать часть пропускной способности для каждого виртуального
канала. В этом случае характеристика трафика выступает в качестве договора об
обслуживании, которое сеть обязуется предоставить пользователю. 

Пример:
![[Pasted image 20241223151030.png]]
Предположим, что хост, подключенный к маршрутизатору A, хочет установить соединение с хостом, соединенным с B. В других обстоятельствах это соединение прошло бы через один из перегруженных маршрутизаторов. Чтобы этого избежать, сеть усекается, как показано на илл. (б). При этом исключаются перегруженные маршрутизаторы и все их линии связи. Пунктиром показан возможный путь виртуального канала в обход перегруженных маршрутизаторов.


#### Сброс нагрузки

Когда ни один из описанных методов не помогает в борьбе с перегрузкой, маршрутизаторы могут ввести в бой тяжелую артиллерию — сброс нагрузки (load
shedding). По сути, **это игнорирование маршрутизаторами пакетов, которые**
**они не могут обработать.**

**Ключевой вопрос для маршрутизатора, заваленного пакетами, — какой из них**
**исключить.** 
Выбор зависит от типа приложений, использующих данную сеть. При передаче файлов более старые пакеты представляют большую ценность, чем новые. 
Есть два варианта:
**Винная стратегия**, это когда старый пакет важнее нового к примеру 
(при передаче больших файлов, например, при загрузке или скачивании документов)
**Молочная стратегия**, это когда новые пакеты важнее старых к примеру (мультимедийных приложений, работающих в реальном времени).
Чтобы реализовать осмысленную стратегию отбрасывания части данных, приложения должны помечать свои пакеты, сообщая сети об их важности. Тогда маршрутизаторы смогут сначала исключить наименее важные пакеты, затем чуть более существенные, и т. д.



## Формирование трафика

**Чтобы гарантировать пользователю определенную производительность, сеть**
**должна знать примерный объем трафика.**
В телефонных сетях его оценить легко: обычный звонок (в несжатом формате) требует скорости 64 Кбит/с и одного 8-битного отсчета каждые 125 мкс. Однако в сетях передачи данных трафик неравномерный (bursty). Он может быть неоднородным по трем причинам: непостоянная скорость передачи (например, при видеоконференциях со сжатием), взаимодействие пользователя и приложения (например, просмотр новой веб-страницы) и переключение компьютера между задачами. С неравномерным трафиком работать гораздо сложнее, чем с постоянным, так как при этом может произойти переполнение буферов и, как следствие, утеря пакетов.

**Шейпинг трафика (traffic shaping)** — способ регулировки средней скорости
и равномерности потока входных данных. Приложения должны иметь возможность передавать тот трафик, который им нужен (включая неравномерный); при
этом нужен простой и удобный способ описания возможных схем трафика. Когда
устанавливается поток, пользователь и сеть (то есть клиент и оператор связи)
договариваются об определенной схеме (то есть форме) трафика для данного
потока. В результате клиент сообщает провайдеру: «Мой график передачи будет
выглядеть следующим образом. Сможете ли вы это обеспечить?» **Иногда такой договор называется соглашением об уровне обслуживания (SLA, Service Level Agreement)**, особенно если в нем оговариваются комплексные потоки и длительные периоды времени (например, весь трафик для данного клиента). До тех пор пока клиент выполняет свою часть условий соглашения и передает пакеты в пределах установленного графика, провайдер обязуется доставлять их в определенный срок.

Принцип следующий: каждый хост соединяется с сетью через интерфейс, содержащий «дырявое ведро». Чтобы пакет можно было отправить в сеть, в ведре должно быть достаточно места для воды. Если в момент поступления пакета ведро заполнено, пакет либо помещается в очередь до тех пор, пока в ведре не освободится достаточно места, либо отвергается. Первый вариант встречается, когда формирование трафика производится операционной системой хоста. Второй — когда проверка трафика, поступающего в сеть, осуществляется аппаратными средствами в сетевом интерфейсе интернет-провайдера. Этот метод был предложен Тернером (Turner, 1986) и называется **алгоритмом дырявого ведра** (leaky bucket algorithm).

То же самое можно представить по-другому: в виде ведра, которое в данный
момент наполняется (см. илл. 5.23 (в)). Вода вытекает из крана со скоростью R,
а объем ведра, как и в предыдущем случае, равен B. Чтобы отправить пакет, необходимо, чтобы из ведра можно было вылить воду (или маркеры — так обычно
называют содержимое ведра), а не налить ее туда. В ведре может содержаться
ограниченное число маркеров (не более B); если ведро пустое, для отправки
пакета необходимо подождать, пока не появятся новые маркеры. Данный метод
называется **алгоритмом маркерного ведра** (token bucket algorithm).
![[Pasted image 20241223162055.png]]
Алгоритмы дырявого и маркерного ведра ограничивают постоянную скорость потока, при этом пропуская кратковременные всплески трафика (также ограниченные максимальным значением) без искусственных задержек. Чтобы снизить нагрузку на сеть, шейпер «дырявого ведра» сглаживает крупные всплески трафика.
![[Pasted image 20241223162555.png]]


## Активное управление очередью

В интернете и многих других компьютерных сетях отправители передают столько трафика, сколько сеть в состоянии успешно доставить. В таком режиме сеть работает до тех пор, пока она не перегружена. **Если перегрузка неизбежна, она просит отправителей снизить скорость передачи данных.** Подобная обратная связь не исключительная, а вполне обычная ситуация, являющаяся частью работы системы. Этот **режим работы называется предотвращением перегрузки (congestion avoidance)** в противопоставление ситуации, в которой сеть уже перегружена.

Несколько подходов к замедлению трафика, применяемых в дейтаграммных сетях и сетях виртуальных каналов. 
**Каждый подход должен решать две проблемы.**
- Предотвращение перегрузки до ее возникновения.
- Обеспечение более точного мониторинга состояния трафика для принятия оперативных решений.

**Решаются данные проблемы данными вариантами:** 

1. Мониторинг ресурсов:

   • Описание: Маршрутизаторы должны непрерывно отслеживать использование своих ресурсов, таких как выходные линии, буферизация очередей и количество потерянных пакетов.

   • Цель: Позволить маршрутизаторам заранее обнаруживать потенциальные перегрузки, чтобы предотвратить их возникновение.

2. Анализ времени ожидания в очереди:

   • Описание: Время ожидания пакетов в очереди маршрутизатора является индикатором нагрузки. При увеличении трафика время ожидания возрастает.

   • Цель: Этот метод предоставляет более точное представление о текущем состоянии трафика и позволяет быстрее реагировать на изменения, чем просто отслеживание среднего использования линий или количества потерянных пакетов.

##### Алгоритм произвольным ранним обнаружением перегрузки (Random Early Detection, RED). 
Чтобы определить, когда следует удалять пакеты, маршрутизаторы постоянно высчитывают скользящее среднее длин своих очередей. Если средняя длина очереди на каком-либо соединении превышает пороговое значение, эта линия объявляется перегруженной и небольшая часть пакетов удаляется случайным образом. 
**Именно случайный выбор увеличивает вероятность того, что** самые быстрые отправители обнаружат утерю пакета. Это наилучший вариант, поскольку маршрутизатор не знает, какой именно источник является самым проблемным в дейтаграммной сети. Отправитель заметит утерю пакета без всяких уведомлений, после чего транспортный протокол замедлит работу. Таким образом, утерянный пакет несет ту же информацию, что и пакет уведомления, но неявно, без отправки маршрутизатором прямого сигнала.

##### Сдерживающие пакеты.
Самый простой способ уведомить отправителя о перегрузке — сообщить об
этом прямо. При таком подходе маршрутизатор выбирает перегружающий пакет и отправляет источнику сдерживающий пакет (choke packet). На ранних этапах развития интернета в качестве сдерживающего пакета использовалось сообщение SOURCE QUENCH (Постел; Postel, 1981). Оно не прижилось отчасти потому, что не были четко определены условия и результаты его рассылки. 

##### Явное уведомление о перегрузке
Вместо создания дополнительных пакетов маршрутизатор может добавить специальную метку (например, 1 или 0 в заголовке) в любой передаваемый пакет, тем самым сообщая о перегрузке. Когда пакет будет доставлен, получатель поймет, что сеть перегружена, и добавит эту информацию в ответный пакет. После этого отправитель сможет, как и раньше, регулировать свой трафик. Этот **метод называется явным уведомлением о перегрузке (Explicit Congestion Notification, ECN)**
На информацию о перегрузке в заголовке пакета отводится два бита. В момент отправки пакет не имеет метки (илл. 5.25). При проходе через перегруженный маршрутизатор пакет получает отметку о перегрузке. Затем получатель передает эти сведения отправителю, добавив явное уведомление в следующий ответный пакет.
![[Pasted image 20241223170529.png]]


##### Обратное давление на ретрансляционных участках
При высоких скоростях или больших расстояниях до хостов множество новых пакетов может быть передано даже после отправки уведомлений о перегрузке, поскольку реакция на них занимает некоторое время.
Заключается в том, что сдерживающий пакет влияет на трафик каждого маршрутизатора, через который он проходит. Как только сдерживающий пакет достигает точки F, поток данных от F в сторону D должен снизиться. Таким образом, F резервирует для соединения большее количество буферной памяти: источник все еще продолжает заваливать это направление своими данными. Нагрузка на D мгновенно снижается, как головная боль — от таблетки в телевизионной рекламе. На следующем шаге сдерживающий пакет, продолжая свой путь, достигает E и приказывает уменьшить поток в сторону F. В результате точке E приходится выдерживать повышенную нагрузку, но зато F немедленно становится легче. Наконец, победный марш сдерживающего пакета приводит его к источнику всех бед — точке A, и теперь поток снижается по-настоящему. Результат применения этой схемы — максимально быстрое устранение перегрузки на самом проблемном участке за счет использования большего объема буферной памяти промежуточных маршрутизаторов.
![[Pasted image 20241223171245.png]]